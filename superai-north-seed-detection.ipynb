{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install 'git+https://github.com/facebookresearch/detectron2.git'","metadata":{"execution":{"iopub.status.busy":"2023-06-17T06:25:55.771833Z","iopub.execute_input":"2023-06-17T06:25:55.772545Z","iopub.status.idle":"2023-06-17T06:29:26.135230Z","shell.execute_reply.started":"2023-06-17T06:25:55.772511Z","shell.execute_reply":"2023-06-17T06:29:26.134056Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport json\nimport cv2\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nfrom collections import defaultdict\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor, DefaultTrainer\nfrom detectron2.config import get_cfg\nfrom detectron2.data.datasets import register_coco_instances\nfrom detectron2.data import MetadataCatalog","metadata":{"execution":{"iopub.status.busy":"2023-06-17T06:29:26.137764Z","iopub.execute_input":"2023-06-17T06:29:26.138170Z","iopub.status.idle":"2023-06-17T06:29:28.298989Z","shell.execute_reply.started":"2023-06-17T06:29:26.138129Z","shell.execute_reply":"2023-06-17T06:29:28.297984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Register a COCO format dataset to Detectron2\nregister_coco_instances(\"train_seed\", {}, \n    \"/kaggle/input/superai-north-seed-detection/boundarybox_seed_train.json\", \n    \"/kaggle/input/superai-north-seed-detection/train\")\n\nseed_metadata = MetadataCatalog.get(\"train_seed\")","metadata":{"execution":{"iopub.status.busy":"2023-06-17T06:29:28.300440Z","iopub.execute_input":"2023-06-17T06:29:28.301095Z","iopub.status.idle":"2023-06-17T06:29:28.309445Z","shell.execute_reply.started":"2023-06-17T06:29:28.301063Z","shell.execute_reply":"2023-06-17T06:29:28.308611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set up training configuration\ncfg = get_cfg()\ncfg.merge_from_file(model_zoo.get_config_file('LVISv0.5-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_1x.yaml'))\ncfg.DATASETS.TRAIN = (\"train_seed\",)\ncfg.DATASETS.TEST = ()\ncfg.DATALOADER.NUM_WORKERS = 2\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url('LVISv0.5-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_1x.yaml')  # Let training initialize from model zoo\ncfg.SOLVER.IMS_PER_BATCH = 2\ncfg.SOLVER.BASE_LR = 0.00025\ncfg.SOLVER.MAX_ITER = 300    # 300 iterations seems good enough, but you can certainly train longer\ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 20  # you have 20 classes of seeds","metadata":{"execution":{"iopub.status.busy":"2023-06-17T06:32:57.262024Z","iopub.execute_input":"2023-06-17T06:32:57.263161Z","iopub.status.idle":"2023-06-17T06:32:57.290518Z","shell.execute_reply.started":"2023-06-17T06:32:57.263125Z","shell.execute_reply":"2023-06-17T06:32:57.289552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\ntrainer = DefaultTrainer(cfg) \ntrainer.resume_or_load(resume=False)\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-06-17T06:33:01.441607Z","iopub.execute_input":"2023-06-17T06:33:01.442361Z","iopub.status.idle":"2023-06-17T06:38:45.181365Z","shell.execute_reply.started":"2023-06-17T06:33:01.442317Z","shell.execute_reply":"2023-06-17T06:38:45.180025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set up prediction configuration\ncfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.2\n# cfg.DATASETS.TEST = (\"seed_train\", )\npredictor = DefaultPredictor(cfg)","metadata":{"execution":{"iopub.status.busy":"2023-06-17T06:54:29.052674Z","iopub.execute_input":"2023-06-17T06:54:29.053092Z","iopub.status.idle":"2023-06-17T06:54:31.181098Z","shell.execute_reply.started":"2023-06-17T06:54:29.053063Z","shell.execute_reply":"2023-06-17T06:54:31.180143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"def auto_crop(image_path):\n    # Load image\n    img = cv2.imread(image_path)\n\n    # Convert the image to grayscale\n    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\n    # Apply Gaussian blur\n    blur = cv2.GaussianBlur(gray, (5,5), 0)\n\n    # Threshold the image\n    _, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n\n    # Find contours in the binary image\n    contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n\n    # Find bounding rectangles for each contour\n    rects = [cv2.boundingRect(cnt) for cnt in contours]\n\n    # Find the combined bounding box\n    top_x = min([x for (x, y, w, h) in rects])\n    top_y = min([y for (x, y, w, h) in rects])\n    bottom_x = max([x+w for (x, y, w, h) in rects])\n    bottom_y = max([y+h for (x, y, w, h) in rects])\n\n    # Crop the image with the dimensions of the bounding box\n    cropped = img[top_y:bottom_y, top_x:bottom_x]\n\n    # Resize the image\n    resized = cv2.resize(cropped, (3648, 2736))\n\n    return resized\n\n# Use the function to auto-crop an image\ncropped_img = auto_crop('/kaggle/input/superai-north-seed-detection/test/150.jpg')\n\n# Show the cropped image\nplt.imshow(cv2.cvtColor(cropped_img, cv2.COLOR_BGR2RGB))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-17T06:45:52.214264Z","iopub.execute_input":"2023-06-17T06:45:52.214632Z","iopub.status.idle":"2023-06-17T06:45:53.988359Z","shell.execute_reply.started":"2023-06-17T06:45:52.214603Z","shell.execute_reply":"2023-06-17T06:45:53.978993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Directory containing images to be cropped\nsource_dir = '/kaggle/input/superai-north-seed-detection/test'\n\n# Directory to save cropped images\ndest_dir = './cropped_img'\n\n# Create the destination directory if it does not exist\nos.makedirs(dest_dir, exist_ok=True)\n\n# Iterate over all images in the source directory\nfor filename in os.listdir(source_dir):\n    # Ensure the file is an image\n    if filename.endswith(\".jpg\"):\n        # Construct full image path\n        image_path = os.path.join(source_dir, filename)\n        \n        # Auto crop the image\n        cropped_img = auto_crop(image_path)\n        \n        # Save the cropped image to the destination directory\n        cv2.imwrite(os.path.join(dest_dir, \"\" + filename), cropped_img)","metadata":{"execution":{"iopub.status.busy":"2023-06-17T06:46:23.009582Z","iopub.execute_input":"2023-06-17T06:46:23.010009Z","iopub.status.idle":"2023-06-17T06:47:02.402515Z","shell.execute_reply.started":"2023-06-17T06:46:23.009967Z","shell.execute_reply":"2023-06-17T06:47:02.401350Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from detectron2.utils.visualizer import Visualizer\nfrom detectron2.data import MetadataCatalog\n\n# select an image file\nfilename = \"105.jpg\"   # replace with your image file name\nimg_path = os.path.join(\"/kaggle/working/cropped_img/\", filename)\n\n# load the image with OpenCV\nimg = cv2.imread(img_path)\n\n# make a prediction with the model\noutputss = predictor(img)\n\n# create a Visualizer instance\nv = Visualizer(img[:, :, ::-1], metadata=MetadataCatalog.get(\"seed_train\"), scale=1.2)\n\n# overlay the predictions on the image\nv = v.draw_instance_predictions(outputss[\"instances\"].to(\"cpu\"))\n\n# display the image\nplt.imshow(v.get_image()[:, :, ::-1])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-17T06:51:09.266959Z","iopub.execute_input":"2023-06-17T06:51:09.267341Z","iopub.status.idle":"2023-06-17T06:51:13.181189Z","shell.execute_reply.started":"2023-06-17T06:51:09.267313Z","shell.execute_reply":"2023-06-17T06:51:13.180382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# location of submission data\nsubmission_dir = '/kaggle/working/cropped_img'\n# get the list of submission image files\nsub_files = os.listdir(submission_dir)\nprint(sub_files)\nprint(len(sub_files))","metadata":{"execution":{"iopub.status.busy":"2023-06-17T06:51:35.403272Z","iopub.execute_input":"2023-06-17T06:51:35.403675Z","iopub.status.idle":"2023-06-17T06:51:35.410534Z","shell.execute_reply.started":"2023-06-17T06:51:35.403646Z","shell.execute_reply":"2023-06-17T06:51:35.409603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# initialize dictionary to hold counts\ncounts = defaultdict(lambda: [0]*20)\n\nfor filename in sub_files:\n    if filename.endswith(\".jpg\"):   # make sure we're working with an image\n        # read the image file\n        img = cv2.imread(os.path.join(submission_dir, filename))\n        \n        # use the predictor on the image\n        outputs = predictor(img)\n        \n        # get the predicted classes for each instance\n        classes = outputs[\"instances\"].pred_classes.to(\"cpu\").numpy()\n\n        # increment the count for each class\n        for class_id in classes:\n            counts[filename][class_id] += 1\n        \n        # if no classes were found, ensure the image still gets added to the dictionary with zero counts\n        if filename not in counts:\n            counts[filename] = [0]*20","metadata":{"execution":{"iopub.status.busy":"2023-06-17T06:55:01.166117Z","iopub.execute_input":"2023-06-17T06:55:01.166479Z","iopub.status.idle":"2023-06-17T06:55:38.871669Z","shell.execute_reply.started":"2023-06-17T06:55:01.166450Z","shell.execute_reply":"2023-06-17T06:55:38.870706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert counts to a dataframe\ndf = pd.DataFrame(counts).T\n\n# if any images had no instances of a class, fill that with 0\ndf.fillna(0, inplace=True)\n\n# name columns with class names\ndf.columns = seed_metadata.thing_classes\ndf.index.name = 'id'\ndf","metadata":{"execution":{"iopub.status.busy":"2023-06-17T06:55:42.358552Z","iopub.execute_input":"2023-06-17T06:55:42.359243Z","iopub.status.idle":"2023-06-17T06:55:42.387809Z","shell.execute_reply.started":"2023-06-17T06:55:42.359209Z","shell.execute_reply":"2023-06-17T06:55:42.386966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# write the dataframe to a csv file\ndf.to_csv('seed08.csv')","metadata":{"execution":{"iopub.status.busy":"2023-06-17T06:55:47.489867Z","iopub.execute_input":"2023-06-17T06:55:47.490936Z","iopub.status.idle":"2023-06-17T06:55:47.497732Z","shell.execute_reply.started":"2023-06-17T06:55:47.490878Z","shell.execute_reply":"2023-06-17T06:55:47.496698Z"},"trusted":true},"execution_count":null,"outputs":[]}]}